{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"About to start the program\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import operator\n",
    "# from imblearn.over_sampling import ADASYN, RandomOverSampler, SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import tree, neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import log_loss\n",
    "#  from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Install the dataset of historic loan data\n",
    "print(\"About to input the csv file\")\n",
    "BankLoans = pd.read_csv(\"Loans.csv\")\n",
    "pd.unique(BankLoans['loan_status'].values.ravel())\n",
    "print(\"Number of distinct classes is\", len(pd.unique(BankLoans['loan_status'].values.ravel())))\n",
    "# Converting 'emp_length' column into an integer numeral by removing the word 'years' from each value \n",
    "BankLoans['emp_length'] = BankLoans[\"emp_length\"].replace({'years':'','year':'',' ':'','<':'','\\+':'','n/a':'0'}, regex = True)\n",
    "BankLoans.emp_length=BankLoans.emp_length.astype(int)\n",
    "# Setting X, the set of independent variables, and Y which is the Target class whoich is loan_status\n",
    "X = BankLoans.drop(\"loan_status\", axis =1, inplace = False)\n",
    "y = BankLoans.loan_status  \n",
    "# Dropping columns which are at least 80% NA data values  \n",
    "BankLoans = BankLoans.dropna(axis=1, thresh=int(0.80*len(BankLoans)))\n",
    "# Eliminating duplicates\n",
    "BankLoans.drop_duplicates(keep='first',inplace=True)\n",
    "def HotEncodedMatrix(DaFrame, Colums) : \n",
    "    DumVars = pd.get_dummies(DaFrame[Colums])\n",
    "    DaFrame = DaFrame.drop(Colums, axis = 1,inplace=False)\n",
    "    NewFrame = DaFrame.join(DumVars)\n",
    "    return NewFrame\n",
    "X = HotEncodedMatrix(X, ['grade', 'emp_length', 'home_ownership', 'verification_status', 'pymnt_plan', 'initial_list_status', 'application_type', 'verification_status_joint'])\n",
    "XNew = X.fillna(value = 0)\n",
    "print(\"just got to running HotEncodedMatrix\")\n",
    "# Defining function taking a confusion matriz as argument   \n",
    "def Confusion(ConfMat):\n",
    "    fig, axes = plt.subplots(figsize=(8,6))\n",
    "    ConfMat = cm.astype('float')/cm.sum(axis=0)\n",
    "    ax = sns.heatmap(ConfMat, annot=True, cmap='Blues');\n",
    "    ax.set_xlabel('True Label')\n",
    "    ax.set_ylabel('Predicted Label')\n",
    "    ax.axis('equal')\n",
    "# Divide the data into Testing and Training datasets with 30% of the data into the Testing set and 70% if the data in the Training set\n",
    "X_train, X_test, y_train, y_test  = train_test_split(XNew, y, test_size=.3, rand_state=123)\n",
    "yTestLoanStatus = y_train['Loan_Status'].values \n",
    "# Applying SMOTE (Synthetic Minority Over-Sampling) which is a method applied to analyzing imbalanced \n",
    "# datasets, for example the Training datasets versus the Testing datasets\n",
    "sm = SMOTE(random_state=0)\n",
    "Xsmote, ysmote = sm.fit_sample\n",
    "np.bincount(yTrainSmote)\n",
    "# Normalizing the data to ahive data stanardization so that mean average is equal to zero\n",
    "scaler = StandardScaler\n",
    "Xstd = scaler.fit_transform(Xsmote)\n",
    "XTestStd = scaler.fit_transform(X_test)\n",
    "# Logistic Regression Section \n",
    "LogReg = LogisticRegression(C=1, solver = 'liblinear')\n",
    "LogReg.fit(X_train, y_train)\n",
    "yTestPred = LogReg.predict(X_test)\n",
    "LogRegConfusion = confusion_matrix(y_pred=yTestPred, yReal=y_test)\n",
    "Confusion(LogRegConfusion)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred=yTestPred))\n",
    "# Decision Tree section \n",
    "DeciTree = DecisionTreeClassifier(min_samples_split=30, min_samples_leaf=10, random_state=10)\n",
    "DeciTree.fit(X_train, y_train)\n",
    "yTestPred = DeciTree.predict(X_test)\n",
    "DeciTreeConfusion = confusion_matrix(yPredicted=yTestPred, yReal=y_test)\n",
    "Confusion(DeciTreeConfusion)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, yPredicted=yTestPred))\n",
    "# Support Vector Machine (SVM) section\n",
    "SVMachine = SVC(random_state=42, tol=100,class_weight='balanced')\n",
    "SVMachine.fit(X_train,y_train)\n",
    "SVMachine\n",
    "# K Nearest Neighbors (KNN) section \n",
    "# KNN_BankLoans = KNeighborsClassifier(n_neighbors = 10, metric='Euclidean')\n",
    "# KNN_BankLoans\n",
    "# KNN_BankLoans.fit(X_train, y_train)  \n",
    "# KNN_BankLoans.predict(X_test) \n",
    "\n",
    "# Measuring the statistical Goodness of Fit by R_Squared tests respectively on the Training\n",
    "# dataset and on the testing dataset\n",
    "# TestingDataRSquared = KNN_BankLoans.score(X_test, y_test) \n",
    "# TrainingDataRSquared = KNN_BankLoans.score(X_train, y_train)\n",
    "# print(\"The R-Squared of the Training dataset is : \", TrainingDataRSquared)\n",
    "# print(\"The R_Squared of the Testing dataset is:\", TestingDataRSquared)\n",
    "# Next, display the confusion matrix\n",
    "# KNN_Confusion = confusion_matrix(y_true = y_test, y_pred = KNN_BankLoans.predict(X_test)) \n",
    "# print(\"Confusion matrix is shown directly below :\")\n",
    "print(KNN_Confusion)\n",
    "# KNN_ClassificationReport = classification_report(y_true = y_test, y_predicted = KNN_BankLoans(X_test))\n",
    "# print(KNN_ClassificationReport)\n",
    "\n",
    "# Assessing the accuracy of different potental values for K in the K nearest Neighbors (KNN) procedure\n",
    "Score = 0\n",
    "ScoreOld = 0\n",
    "KSelected = 0\n",
    "Kayes = range(1, 12)\n",
    "K_Select = []\n",
    "for K in Kayes:\n",
    "    KNN_BankLoans = KNeighborsClassifier(n_neighbors = K).fit(X_train, y_train)\n",
    "    YTestPred = KNNBankLoans.predict(X_test)\\\n",
    " #   Jack = round(jaccard_similarity_score(y_test, yTestPred),2)\n",
    " #  if ScoreOld < Jack :\n",
    " #       Score = Jack\n",
    " #       KSelected = K\n",
    "#        ScoreOld = Jack\n",
    "    print(\"Test set Accuracy at k=\", k, \": \", jaccard_similarity_score(y_test, yTestPred))\n",
    "    K_Select.append(jaccard_similarity_score(y_test, yTestPred))\n",
    "# plot the relationship between K and testing accuracy\n",
    "plt.plot(Kayes, K_Select)\n",
    "plt.xlabel('Potential Values of K for K Nearest Neighbors')\n",
    "plt.ylabel('Testing Accuracy')   \n",
    "# Accuracy checks section : \n",
    "# Jaccard setup\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "# Checking accuracy of K Nearest Neighbors (KNN)\n",
    "yTestPred_KNN = KNN_BankLoans.predict(XTestStd)\n",
    "Jack1 = round(jaccard_similarity_score(yTestLoanStatus, yTestPred_KNN), 2)\n",
    "# evaluate Decision Trees\n",
    "yTestPred_DeciTree = DeciTree.predict(XTestStd)\n",
    "Jack2 = round(jaccard_similarity_score(yTestLoanStatus, yTestPred_DeciTree), 2)\n",
    "#evaluate SVM\n",
    "yTestPred_SVM = SVMachine.predict(XTestStd)\n",
    "Jack3 = round(jaccard_similarity_score(yTestLoanStatus, yTestPred_SVM), 2)\n",
    "# evaluate Logistic Regression\n",
    "yTestPred_LogReg = LogReg.predict(XTestStd)\n",
    "Jack4 = round(jaccard_similarity_score(yTestLoanStatus, yTestPred_LogReg), 2)\n",
    "\n",
    "Lists_of_Jack = [Jack1, Jack2, Jack3, Jack4]\n",
    "Lists_of_Jack\n",
    "\n",
    "# F1-score setup\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# evaluate KNN\n",
    "f1_KNN = round(f1_score(y_TestLoanStatus, yTestPred_KNN, average='weighted'), 2)\n",
    "# evaluate Desision Trees \n",
    "f1_DeciTree = round(f1_score(y_TestLoanStatus, yTestPred_DeciTree, average='weighted'), 2)\n",
    "# evaluate SVM\n",
    "f1_SVM = round(f1_score(y_TestLoanStatus, yTestPred_SVM, average='weighted'), 2)\n",
    "# evaluate Logistic Regression\n",
    "f1_LogReg = round(f1_score(yTestLOanStatus, yTestPred_LogReg, average='weighted'),2 )\n",
    "\n",
    "f1_list = [f1_KNN, f1_DeciTree, f1_SVM, f1_LogReg]\n",
    "f1_List\n",
    "# LogLoss\n",
    "from sklearn.metrics import log_loss\n",
    "LR_Predict_Proba = LR.predict_proba(XTestStd)\n",
    "list_ll = ['NA', 'NA', 'NA', round(log_loss(y_TestLoanStatus, LR_Predict_Proba), 2)]\n",
    "list_ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
